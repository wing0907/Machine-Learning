import pandas as pd
import numpy as np
import random
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, LabelEncoder
from xgboost import XGBClassifier

# Seed
seed = 123
random.seed(seed)
np.random.seed(seed)

# 1. ë°ì´í„° ë¡œë“œ
path = './_data/kaggle/otto/'
train_csv = pd.read_csv(path + 'train.csv', index_col=0)
x = train_csv.drop(['target'], axis=1)
y = train_csv['target']

# target â†’ ìˆ«ìí˜• ì¸ì½”ë”©
le = LabelEncoder()
y_encoded = le.fit_transform(y)  # 'Class_1' â†’ 0, ..., 'Class_9' â†’ 8

# ìŠ¤ì¼€ì¼ë§
scaler = RobustScaler()
x_scaled = scaler.fit_transform(x)

# train/test ë¶„ë¦¬
x_train, x_test, y_train, y_test = train_test_split(
    x_scaled, y_encoded, test_size=0.2, random_state=seed, stratify=y_encoded
)

# ëª¨ë¸ í•™ìŠµ
model = XGBClassifier(random_state=seed)
model.fit(x_train, y_train)
print("ğŸ”¥ ì œê±° ì „ acc:", model.score(x_test, y_test))

# Feature importance ê¸°ì¤€ í•˜ìœ„ 25% ì œê±°
importances = model.feature_importances_
threshold = np.percentile(importances, 25)
low_idx = np.where(importances <= threshold)[0]

# ë¶ˆí•„ìš”í•œ feature ì œê±°
x_reduced = pd.DataFrame(x_scaled).drop(columns=low_idx)

# ë‹¤ì‹œ ë°ì´í„° ë¶„ë¦¬
x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(
    x_reduced, y_encoded, test_size=0.2, random_state=seed, stratify=y_encoded
)

# ì¬í•™ìŠµ
model.fit(x_train_r, y_train_r)
print("âœ… ì œê±° í›„ acc:", model.score(x_test_r, y_test_r))

# ğŸ”¥ ì œê±° ì „ acc: 0.8116515837104072
# âœ… ì œê±° í›„ acc: 0.8106819650937298